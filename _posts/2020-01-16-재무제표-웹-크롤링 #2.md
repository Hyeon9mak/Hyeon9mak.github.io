---
title: "[Python 재무제표 크롤링 #2] 설계 및 구현 고도화"
date: 2020-01-16 16:30:00
categories:
    - Python
tags:
    - Python
    - 파이썬
    - 재무제표
    - crolling
    - 크롤링
toc: true
toc_sticky: true
toc_label: "[Python 재무제표 크롤링 #2]"
---

이번 글에서는 [[Python 재무제표 크롤링 #2] 요구사항, 재무제표 분석 및 설계](https://hyeon9mak.github.io/python/%EC%9E%AC%EB%AC%B4%EC%A0%9C%ED%91%9C-%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-1/)에서 작성했던 코드를 다듬고, 
실행 결과 파일 저장명을 기업명(또는 기업종목코드)와 해당 보고서명의 조합으로 저장하기 위한 코드를 추가했다.  
또한 재무상태표의 표만을 엑셀에 저장하는 것이 아닌, 재무상태표의 속성정보(기재 날짜, 단위 등)를 표현할 수 있는 방법에 대해 
고민해보았고, 이를 여러 번의 테스트 끝에 실제 코드로 구현에 성공했다.

## 분석 및 설계
- 결과 파일의 이름을 [기업명(기업종목코드) 보고서명]으로 저장하기 위한 코드 수정

- 재무상태표 상단에 재무상태표가 가지는 정보들 (단위 등)을 표기할 수 있는 방안 고찰
    1. 기존 Dataframe타입 변수에서 재무상태표 정보를 가져오는 테스트, 실패.
    2. 추가적인 파싱 작업을 통하여 재무상태표 정보를 새로이 가져오는 테스트, 성공!
    3. 엑셀 파일로 저장하기 전, Dataframe 최상단 행(row)에 재무상태표 정보를 추가하는 방안 테스트, 실패.  
        일반적인 방법으로는 Dataframe 최상단 행(row)에 데이터를 추가하기 까다로웠으며, 서로 가지는 열(Column)이 뒤섞이는 문제 발생
    4. 재무상태표 정보를 담은 Dataframe과 재무상태표 Dataframe 2개로 나누어 한꺼번에 엑셀 파일로 저장하는 테스트, 실패.
        행(row)이 뒤섞이거나, 불필요한 열(column)이 계속해서 표기 되는 문제 발생
    5. 재무상태표 정보 Dataframe과 재무상태표 Dataframe을 순차적으로 같은 파일에 저장하는 테스트 진행, 성공!  
        엑셀 파일 저장에 사용되는 'to_csv()' 함수의 인자로 불필요한 행(row)와 열(column) 표기를 제거하거나, 덮어쓰기와 이어쓰기 선택이 가능했음.

- 재무상태표 상단에 재무상태표의 단위와 기타 속성 정보들을 표기할 수 있도록 코드 추가

- 탐색 성공 여부와, 탐색 실패시 어떠한 영역에서 실패하였는지 출력하는 코드 추가

- 연결재무제표와 개별재무제표를 하나의 엑셀 파일에 저장할 수 있는 방안 고찰  
    반복사용되는 코드 영역을 개별 함수로 분리하고, 연결재무제표 페이지와 개별재무제표 페이지로 넘어가는 URL을 각각 구해서 
    분리한 함수에 인자로 넘겨줄 수 있도록 코드를 추가 및 수정함.

- 추가 및 수정된 코드 테스트 진행. 성공적으로 저장되는 모습을 확인 함.



## 작성 코드

```python
from bs4 import BeautifulSoup                            # for html parser
from urllib.request import urlopen                       # for html request/respone
import pandas as pd                                      # for DataFrame
from html_table_parser import parser_functions as parser #for parsing

API_KEY = "" # API 이용에 필요한 인증번호
COMPANY_CODE = input("기업종목코드 6자리 : ")

###########################################################################################################
# 기업종목번호 기반 전체 사업보고서 검색 함수                                                                #
# Input : NULL       /       Output : DataFrame                                                           #
###########################################################################################################
def searching_report() :                    
    SEARCH_URL = "http://dart.fss.or.kr/api/search.xml?auth=" + API_KEY + "&crp_cd=" + COMPANY_CODE
    SEARCH_URL = SEARCH_URL + "&start_dt=19990101&bsn_tp=A001&fin_rpt=Y"    #검색날짜 범위 / 사업보고서 / 최종보고서만
    XML_RESULT = BeautifulSoup(urlopen(SEARCH_URL).read(), 'html.parser')

    find_list = XML_RESULT.findAll("list")  # list태그를 모두 탐색
    data = pd.DataFrame()                   # 데이터를 저장할 프레임 선언
    for t in find_list :                    # 나열번호, 기업명, 기업번호, 보고서명, 보고서번호, 제출인,  접수일자, 비고
        temp = pd.DataFrame(([[t.crp_cls.string, t.crp_nm.string, t.crp_cd.string, t.rpt_nm.string,
                t.rcp_no.string, t.flr_nm.string, t.rcp_dt.string, t.rmk.string]]),
                columns = ["crp_cls", "crp_nm", "crp_cd", "rpt_nm", "rcp_no", "flr_nm", "rcp_dt", "rmk"])
        data = pd.concat([data, temp])
    
    if len(data) < 1 :                      # 검색 결과가 없을 시.
        return None

    del data['crp_cls']
    del data['crp_cd']                      # 나열번호, 기업번호 제거 (불필요)
    data = data.reset_index(drop=True)

    return data

###########################################################################################################
# 검색된 전체 사업보고서 기반 재무제표 페이지 이동 함수                                                       #
# Input : NULL       /       Output : NULL                                                                #
###########################################################################################################
def fs_page() :
    data = searching_report()
    if len(data) < 1 :
        print("!!!! 실패 : 사업보고서 검색 결과 없음.")
        return 0

    document_count = 0

    for i in range(len(data)) :
        MAIN_URL = "http://dart.fss.or.kr/dsaf001/main.do?rcpNo=" + data['rcp_no'][document_count]
        link_flag = 1
        indi_flag = 1

        page = BeautifulSoup(urlopen(MAIN_URL).read(), 'html.parser')
        body = str(page.find('head'))

        if len(body.split('연결재무제표",')) <= 1 :             # 연결재무제표 탐색 시작
            if len(body.split('연 결 재 무 제 표",')) >=2 : 
                body = body.split('연 결 재 무 제 표",')[1]     # "연 결 재 무 제 표" 로 발견
                link_page_1 = '연 결 재 무 제 표'
            else :                                             # 실패시 경고 문구
                print("!!!! 실패 : " + data['rpt_nm'][document_count] + " / 연결재무제표 페이지 탐색 실패함.")
                link_flag = 0         #연결 재무제표 없음
        else :
            body = body.split('연결재무제표",')[1]              # "연결재무제표" 로 발견
            link_page_1 = '연결재무제표'
        
        indi_body = body;        
        if len(indi_body.split('재무제표",')) <= 1:             # 개별재무제표 탐색 시작
            if len(indi_body.split('재 무 제 표",')) >= 2:
                indi_body = indi_body.split('재 무 제 표",')[1] # "재 무 제 표" 로 발견
                indi_page_1 = '재 무 제 표'
            else :                                             # 실패시 경고 문구
                print("!!!! 실패 : " + data['rpt_nm'][document_count] + " / 재무제표 페이지 탐색 실패함.")
                indi_flag = 0           #개별 재무제표 없음
        else :
            indi_body = indi_body.split('재무제표",')[1]        # "재무제표" 로 발견
            indi_page_1 = '재무제표'

        if(link_flag == 1) : fs_table(body, data, document_count, link_page_1)      # 연결 재무제표가 있으면
        if(indi_flag == 1) : fs_table(indi_body, data, document_count, indi_page_1) # 개별 재무제표가 있으면

        document_count += 1
    return

###########################################################################################################
# 목차를 통해 이동한 페이지에서 표 값들을 추출하는 함수                                                       #
# Input : string, DataFrame, int, string       /       Output : NULL                                      #
###########################################################################################################
def fs_table(body, data, document_count, page_1) :
    body = body.split('cnt++')[0].split('viewDoc(')[1].split(')')[0].split(', ')
    body = [body[i][1:-1] for i in range(len(body))]       # 찾아낸 재무제표 페이지로 이동하기 위한 url구성 번호 파싱
    VIEWER_URL = "http://dart.fss.or.kr/report/viewer.do?rcpNo=" + body[0] \
                + '&dcmNo=' + body[1] + '&eleId=' + body[2] + '&offset=' + body[3] \
                + '&length=' + body[4] + '&dtd=dart3.xsd'

    table_attribute = BeautifulSoup(urlopen(VIEWER_URL).read(), 'html.parser')
    table_attribute = table_attribute.find('table') # 가장 먼저 등장하는 table태그 기준 가져오기
    pt = parser.make2d(table_attribute)             # list로 변환저장 - 과정에서 다른 불필요한 태그들 자동 제거
    table_attribute = pd.DataFrame(pt)              # DataFrame으로 변환하여 다시저장
    
    table_attribute = table_attribute.applymap(lambda x: x.replace('\xa0','').replace('\xa9','')) #인코딩을 위해 공백을 의미하는 특수문자열 제거
    table_attribute.to_csv('C:\\Users\\admin\\Desktop\\Test_Result\\' + data['crp_nm'][0] + "(" + COMPANY_CODE
                + ") " + data['rpt_nm'][document_count] +'.csv', encoding='cp949', header=False, index=False, mode='a')
                #header를 통해 column명 표기X, index를 통해 row명 표기X, mode w로 파일 덮어쓰기식 생성

    page = BeautifulSoup(urlopen(VIEWER_URL).read(), 'html.parser')
    if len(str(page.find('body')).split('재 무 상 태 표')) == 1 :   # 재무상태표 탐색 시작
        if len(str(page.find('body')).split('재무상태표')) <= 1 :   # 재무상태표를 찾아내지 못한다면 프로그램 종료
            print("### 연결 재무상태표 탐색 실패.")
            return 0
        else :
            body = str(page.find('body')).split('재무상태표')[1]    # "재무상태표" 로 발견
            page_2 = '연결 재무상태표'
    else : 
        body = str(page.find('body')).split('재 무 상 태 표')[1]    # "재 무 상 태 표" 로 발견
        page_2 = '연 결 재 무 상 태 표'
    
    body = BeautifulSoup(body, 'html.parser')                       # 찾아낸 재무상태표를 읽어내기 위해 파싱

    print("탐색 성공 : " + data['rpt_nm'][document_count] + " / " + page_1 + " / " + page_2)
    
    table = body.find_all('table')  # table 태그 탐색
    if len(table) <= 1 :            # 탐색 실패시 프로그램 종료
        print("- " + data['rpt_nm'][document_count] + " / " + page_1 + " / " + page_2 + "### 재무상태표 파싱 실패.")
        return 0

    p = parser.make2d(table[0])    
    table = pd.DataFrame(p[1:], columns = p[0])

    table.to_csv('C:\\Users\\admin\\Desktop\\Test_Result\\' + data['crp_nm'][0] + "(" + COMPANY_CODE
                + ") " + data['rpt_nm'][document_count] +'.csv', encoding='cp949', index=False, mode='a')
                #index를 통해 row명 표기X, mode a로 파일 이어쓰기식 열기
    return

print(fs_page())          # for testing.
```
  
기업종목번호 6자리를 입력 받고, API 키를 이용해 인증 후 재무제표가 포함된 연단위 사업보고서 전체를 검색하는 페이지 URL을 합성하는 과정은 동일하다.
**searching_report()** 함수를 통해 사업보고서 전체를 검색하는 페이지 URL에서 각각 사업보고서의 페이지를 열기 위한 정보들을 모은 다음, 
불필요한 정보는 제거한 뒤 **fs_page()** 함수로 이동한다.  

**fs_page()** 함수로 이동 된 정보들은 사업보고서 복수 개의 정보들이므로, for문을 통해 반복 된다.
가져온 사업보고서의 정보들 중, 사업보고서 번호를 의미하는 *'rcp_no'*를 기본 URL에 첨가하여 
사업보고서 페이지를 구성하는 URL을 합성한다. 합성된 URL에서 가져온 페이지 소스를 BeautifulSoup 모듈을 이용해 html형식으로 읽어들이고, 읽어들인 html형식 소스 중 가장 먼저 등장하는 *<head>* 태그를 찾아낸다.  

## 고찰 및 후기